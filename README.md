# Mohamed Lamine OULD BOUYA  
**Data Scientist ¬∑ Data Engineer ¬∑ Data Analyst ¬∑ IA**

> Je con√ßois des solutions data robustes, explicables et utiles : de l‚Äôingestion √† la mise en production, en passant par la mod√©lisation ML/IA et la data visualisation.

Rueil-Malmaison  
ouldbouya.mohamedlamine@gmail.com  
+33 7 60 15 54 08  
Objectif : **stage de fin d‚Äô√©tudes (6 mois)** √† partir de d√©but janvier 2026  
Int√©r√™ts : Machine Learning - Data visulisation - IA g√©n√©rative - Qualit√© des donn√©es - Deep learning - Cloud - ETL

---

## √Ä propos de moi

Actuellement en **Mast√®re Sp√©cialis√© Expert Big Data Engineer √† l'Universit√© de Technologie de Troyes (UTT)**, je combine un parcours **ing√©nieur** (analyse de risques, reporting automatis√©, data qualit√©) et une solide formation en **science des donn√©es**.  
Je m‚Äôint√©resse particuli√®rement √† la cr√©ation de pipelines de donn√©es robustes, √† l'analyse et la visualisation via API, √† l'IA g√©n√©rative, √† la mod√©lisation et la mise en production de mod√®les IA.

---

## Projets phares

### 1. [Everflow API Analytics](https://github.com/Momo3972/Everflow-API-Analytics)

> D√©veloppement d‚Äôun mini-syst√®me analytique pour visualiser la performance marketing via l‚ÄôAPI Everflow, incluant l‚Äôextraction de donn√©es, le calcul de m√©triques cl√©s (profit), et la g√©n√©ration automatique de graphiques et d‚Äôun rapport Markdown.

- **Stack** : Python, Pandas, Matplotlib, Requests, Everflow API

- **M√©thodes utilis√©es** :
  - Connexion s√©curis√©e √† l‚ÄôAPI Everflow (authentification via cl√© API)
  - Extraction et transformation de statistiques agr√©g√©es (offres, affili√©s, annonceurs)
  - Calcul du profit (revenue - payout)
  - G√©n√©ration automatique de graphiques analytiques
  - Export automatique d‚Äôun rapport Markdown
  - Structuration modulaire : `src/`, `mock_data/`, `out/`

- **Livrables** :
  - Notebook complet : *Everflow-API-Analytics.ipynb*
  - Rapport Markdown g√©n√©r√© automatiquement
  - Fichiers de sortie dans `out/` :
    - profits par offre
    - profits par affili√©
    - profits par annonceur
    - rapport global (*REPORT*)

- **R√©sultat** :
  D√©ploiement d‚Äôun mini-dashboard analytique automatis√© permettant une visualisation rapide et exploitable des performances marketing via l‚ÄôAPI Everflow.

---

## 2. [Classification d‚ÄôImages CIFAR-10 (CNN et Transfer Learning EfficientNetB0)](https://github.com/Momo3972/deepvision-cifar10-classifier)

> D√©veloppement d‚Äôun syst√®me complet de classification d‚Äôimages bas√© sur le dataset CIFAR-10, incluant un mod√®le CNN construit from scratch et un mod√®le EfficientNetB0 utilisant du Transfer Learning  et du Fine-Tuning pour maximiser les performances

### ‚Ä¢ Stack :
Python, TensorFlow / Keras, NumPy, Matplotlib, Scikit-learn, Google Colab

### ‚Ä¢ Objectif :
Construire et comparer deux approches pour classifier les images CIFAR-10 :

- un mod√®le **CNN baseline** enti√®rement entra√Æn√© from scratch  
- un mod√®le **EfficientNetB0 pr√©-entra√Æn√© sur ImageNet**, puis affin√© (fine-tuning)  
objectif : mesurer l‚Äôimpact du Transfer Learning sur la performance finale

### ‚Ä¢ M√©thodes utilis√©es :

- Exploration et pr√©paration des donn√©es  
- Visualisation d‚Äôexemples CIFAR-10  
- Normalisation des images  
- Cr√©ation de pipelines d‚Äôentra√Ænement, validation et test

### ‚Ä¢ Mod√®le CNN (baseline)

- Architecture personnalis√©e : **Conv2D -> MaxPool > Dropout -> Dense**  
- Entra√Ænement complet sur CIFAR-10  
- Analyse des courbes d‚Äôapprentissage (accuracy / loss)  

### Transfer Learning - EfficientNetB0

- Chargement d‚Äôun mod√®le pr√©-entra√Æn√© (**ImageNet**)  
- Phase 1 : backbone gel√© + classification head personnalis√©e  
- Phase 2 : **fine-tuning** complet  
- Suivi des performances sur les **2 phases concat√©n√©es**

### √âvaluation

- Rapport complet : pr√©cision, rappel, f1-score  
- Matrice de confusion d√©taill√©e  
- Comparaison finale **CNN vs EfficientNetB0**  
- Analyse du gain absolu d‚Äôaccuracy sur le test set  

### R√©sultat
#### CNN baseline :
- **Test accuracy ‚âà 0.70**  
- **Test loss ‚âà 0.86**
#### EfficientNetB0 (Transfer Learning) :
- **Test accuracy ‚âà 0.95**  
- **Test loss ‚âà 0.16**  
- **Gain absolu ‚âà +0.24 en accuracy**

EfficientNetB0 surclasse nettement le CNN baseline sur toutes les classes, confirm√© par les matrices de confusion et les scores F1.

### ‚Ä¢ Livrables :

- Notebook complet : `01_cifar10_cnn.ipynb`  
- Mod√®les entra√Æn√©s :  
  - `cnn_baseline_cifar10.h5`  
  - `efficientnetb0_tl_cifar10.h5`  
- Rapport automatis√© PDF / README du projet  
- Visualisations : courbes d‚Äôapprentissage, matrices de confusion

### R√©sum√©

Ce projet d√©montre l‚Äôint√©r√™t du **Transfer Learning** en vision par ordinateur et met en √©vidence l‚Äô√©cart de performance entre un CNN traditionnel et un mod√®le moderne pr√©-entra√Æn√©.  
EfficientNetB0 montre une am√©lioration substantielle sur la pr√©cision, la robustesse et la g√©n√©ralisation.

---

### 3. [Chatbot RAG IA G√©n√©rative](https://github.com/Momo3972/chatbot-rag-ia-gen)

> D√©veloppement d‚Äôun chatbot IA utilisant une architecture RAG et une interface Web, permettant d‚Äôinterroger dynamiquement une base documentaire PDF et d‚Äôobtenir des r√©ponses contextualis√©es

- **Stack** : Python, LLM (LangChain / OpenAI), RAG, Gradio / Streamlit  

- **Objectif** : permettre √† un utilisateur d‚Äôinterroger des documents (PDF, textes) et d‚Äôobtenir des r√©ponses pr√©cises, contextualis√©es et sourc√©es  

- **M√©thodes utilis√©es** :  
  - Conception d‚Äôune cha√Æne RAG compl√®te : *indexation, embeddings, retrieval, g√©n√©ration*  
  - Int√©gration d‚Äôune API IA (OpenAI / autres LLMs)  
  - Cr√©ation d‚Äôune interface Web interactive (Gradio / Streamlit)  
  - Tests de pertinence et ajustements de la cha√Æne (chunking, embeddings, scoring de similarit√©)  

- **Livrables** :  
  - Application Web interactive pr√™te √† l‚Äôemploi  
  - Cha√Æne RAG compl√®te (*embedding -> retrieval -> g√©n√©ration*)  
  - √âvaluation de la pertinence des r√©ponses et am√©lioration de la qualit√© du chatbot   

---

### 4. [D√©tection de fraude bancaire](https://github.com/Momo3972/projet-fraude)

> Analyse et mod√©lisation de transactions bancaires pour identifier des signaux faibles de fraude dans un contexte de donn√©es fortement d√©s√©quilibr√©es

- **Stack** : Python, Pandas, NumPy, Scikit-learn, XGBoost  
- **Objectif** : am√©liorer le **rappel** de la classe frauduleuse sans d√©grader la **pr√©cision**, dans un dataset o√π les fraudes repr√©sentent <1 % des transactions  
- **M√©thodes utilis√©es** :  
  - Analyse exploratoire (EDA) des variables financi√®res et temporelles  
  - Pr√©paration des donn√©es : nettoyage, encodage, feature engineering  
  - Gestion du d√©s√©quilibre via **SMOTE**  
  - Entra√Ænement et optimisation de mod√®les : **R√©gression Logistique**, **Random Forest**, **XGBoost**  
  - √âvaluation avanc√©e : F1-score, AUC-ROC, courbes pr√©cision-rappel, matrice de confusion  
  - S√©lection du meilleur mod√®le bas√© sur sa capacit√© √† d√©tecter les fraudes rares  
- **R√©sultat** : am√©lioration du **F1-score** et meilleure d√©tection des transactions frauduleuses minoritaires  
- **Livrables** :  
  - Notebook complet `fraude_detection.ipynb`  
  - Visualisations : matrices de confusion, ROC/PR curves, importances des features (`reports/figures/`)  
  - Fichier de m√©triques JSON (`reports/metrics/metrics.json`)  
  - Jeux de donn√©es nettoy√©s (`train_split.csv`, `test_split.csv`)  
  - README structur√© documentant toute la d√©marche   

---

### 5. [Dashboard Power BI - Analyse de la performance commerciale](https://github.com/Momo3972/projet-powerbi-superstore)

> Cr√©ation d‚Äôun tableau de bord interactif pour analyser les ventes, profits et performances commerciales du dataset Global Superstore

- **Stack** : Power BI Desktop, Power Query, DAX, Excel  
- **Objectif** : fournir un tableau de bord professionnel permettant :
  - d‚Äôanalyser l‚Äô√©volution du chiffre d‚Äôaffaires,
  - d‚Äôidentifier les pays contributeurs,
  - de visualiser la r√©partition des ventes par cat√©gories de produits,
  - et de suivre les KPIs essentiels (ventes, profits, volume, marges).

- **M√©thodes utilis√©es** :
  - Analyse des besoins m√©tier et identification des indicateurs cl√©s (KPI)
  - Nettoyage, transformation et mod√©lisation des donn√©es via **Power Query**
  - Mod√©lisation en √©toile (**tables de faits et dimensions**)
  - Cr√©ation de mesures DAX : Total Ventes, Total Profit, Quantit√© vendue, Marge
  - Visualisations avanc√©es :
    - Graphique temporel des ventes (ann√©e / mois)
    - Top 10 des pays par chiffre d‚Äôaffaires
    - R√©partition des ventes par cat√©gorie de produits
  - Filtres dynamiques : ann√©e, segment client, cat√©gorie produit, pays
  - Page d‚Äôinfobulle (tooltip) personnalis√©e pour contextualiser les ventes
  - Page ‚Äú√Ä propos‚Äù documentant la d√©marche analytique

- **Livrables** :
  - Tableau de bord Power BI complet : **analyse des performances commerciales**
  - Visualisations interactives + filtres dynamiques + infobulle contextualis√©e
  - Documentation claire (README + page d√©di√©e dans Power BI)

---

### 6. [Pr√©diction d'un r√©servoir p√©trolier](https://github.com/Momo3972/oil-reservoir-prediction-ml)

> Pr√©diction de la pr√©sence d‚Äôun r√©servoir p√©trolier √† partir de donn√©es g√©ologiques et sismiques simul√©es - avec analyse d‚Äôinterpr√©tabilit√© SHAP pour valider la coh√©rence g√©ologique

- **Stack** : Python, Pandas, NumPy, Scikit-learn, Random Forest, XGBoost, Matplotlib, SHAP
- **Objectif** : pr√©dire la pr√©sence d‚Äôhydrocarbures avant forage, en exploitant des caract√©ristiques g√©ologiques (porosit√©, type de roche, pi√®ge, profondeur, distance aux champs existants, signature sismique)
- **M√©thodes utilis√©es** :
  - Analyse exploratoire (EDA) g√©ologique
  - Pr√©paration des donn√©es & encodage des variables cat√©gorielles
  - Entra√Ænement et optimisation d‚Äôun mod√®le (GridSearchCV)
  - Comparaison de trois mod√®les : **Logistic Regression**, **Random Forest optimis√©**, **XGBoost optimis√©**
  - √âvaluation approfondie (Accuracy, Recall, Precision, F1, ROC-AUC)
  - Interpr√©tabilit√© avanc√©e avec **SHAP** :
    - Summary Plot (vue globale des variables)
    - Force Plot (explication locale d‚Äôune observation)
    - Bar Plot (importance moyenne des features)
- **R√©sultat** :
  - Le **Random Forest optimis√©** obtient le meilleur score (**ROC-AUC ‚âà 0.87**)
  - Les variables les plus d√©terminantes sont :
    - **Seismic_Score** (signal sismique fort -> structures favorables)
    - **Rock_Type** (gr√®s / calcaire -> bons r√©servoirs)
    - **Trap_Type** (anticline / faille / d√¥me -> accumulation d‚Äôhydrocarbures)
    - **Porosity** et **Permeability** (qualit√© du r√©servoir)
    - **Distance aux champs existants**
  - L‚Äôanalyse SHAP confirme que le mod√®le prend des d√©cisions **g√©ologiquement coh√©rentes**
- **Livrables** :
  - Notebook complet d'analyse & mod√©lisation (`oil-prediction.ipynb`)
  - Mod√®le optimis√© export√© : `best_random_forest_oil_reservoir.joblib`
  - Visualisations : matrice de confusion, ROC curve, summary SHAP, force plot, barplot SHAP
  - README complet documentant la d√©marche scientifique et g√©ologique

---

## Comp√©tences techniques

| Domaine | Comp√©tences |
|----------|-------------|
| **Langages** | Python, SQL, R, Excel |
| **Machine Learning** | Scikit-learn, XGBoost, PCA, SMOTE |
| **Deep Learning / Computer vision** | CNN, Transfer Learning, EfficientNet, Python, TensorFlow/Keras, NumPy, Matplotlib, Scikit-learn, Google Colab |
| **Visualisation** | Power BI, Tableau, Plotly, Matplotlib, Seaborn |
| **Base de donn√©es** | MySQL, MongoDB |
| **Cloud / Big Data** | Google Cloud Platform (GCP), Snowflake, Databricks |
| **Data Engineering** | ETL, pipelines, ingestion multi-source, EDA, data quality |
| **Outils / M√©thodo** | Git, VS Code, Jupyter, tests unitaires, documentation |

---

## Formation & Certifications

- **Mast√®re Sp√©cialis√© - Expert Big Data Engineer**, UTT Paris (2024‚Äì2025)  
- **Certificat Concepteur D√©veloppeur en Data Science**, Jedha Paris (2024)  
- **Lean Six Sigma Black Belt**, Cubic Partners Paris (2019)  
- **Master QSE**, EISTI Cergy (2017)  
- **Master G√©osciences**, Universit√© Paris-Saclay (2014)

---

## Exp√©riences professionnelles

### üîπ **AERGON - Ing√©nieur d‚Äô√©tudes** (2019 - aujourd‚Äôhui)
- R√©alisation d‚Äô√©tudes en s√©curit√© et s√ªret√© nucl√©aire
- Audit technique et r√©glementaire en environnement industriel
- Analyse de risques et automatisation de reporting
- Manipulation de jeux de donn√©es r√©glementaires
**Environnement technologique** : Word, Excel, VBA
**Comp√©tences** : rigueur, qualit√© des donn√©es, automatisation, data reporting

### üîπ **IRD - Ing√©nieur stagiaire (mod√©lisation num√©rique)** (2013)
- Int√©gration et interpolation de donn√©es physiques 3D sous GOCAD  
- G√©n√©ration de mod√®les par inversion et analyses exploratoires
**Environnement technologique** : Gocad, Word, Excel
**Comp√©tences** : traitement de donn√©es, interpolation, mod√©lisation scientifique

---

## Soft Skills
- Proactivit√© ¬∑ Curiosit√© intellectuelle ¬∑ Fiabilit√©  
- Esprit d‚Äô√©quipe ¬∑ Communication claire ¬∑ Aisance relationnelle  
- Sens de la rigueur et du r√©sultat  

---

## Centres d‚Äôint√©r√™t
Lecture technique & IA | Football | Cuisine | Po√©sie  

---

## Me retrouver
- **Portfolio en ligne** -> [momo3972.github.io/Portfolio-Data-IA](https://momo3972.github.io/Portfolio-Data-IA/)
- **GitHub** -> [github.com/Momo3972](https://github.com/Momo3972)
- **LinkedIn** -> [https://linkedin.com/in/mohamed-lamineould-bouya-ab465211b](https://linkedin.com/in/mohamed-lamineould-bouya-ab465211b)  

---

> *Je cherche √† rejoindre une √©quipe data ambitieuse pour transformer les donn√©es en valeur m√©tier r√©elle, en combinant rigueur analytique, esprit d‚Äôing√©nierie et cr√©ativit√© IA.*
